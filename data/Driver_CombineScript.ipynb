{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CombineScript.py\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#\n",
    "#                                   ES335- Machine Learning- Assignment 1\n",
    "#\n",
    "# This script combines the data from the UCI HAR Dataset into a more usable format.\n",
    "# The data is combined into a single csv file for each subject and activity. \n",
    "# The data is then stored in the Combined folder.\n",
    "#\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Give the path of the test and train folder of UCI HAR Dataset\n",
    "train_path = \"./UCI HAR Dataset/train\"\n",
    "test_path = \"./UCI HAR Dataset/test\"\n",
    "\n",
    "# Dictionary of activities. Provided by the dataset.\n",
    "ACTIVITIES = {\n",
    "    1: 'WALKING'            ,\n",
    "    2: 'WALKING_UPSTAIRS'   ,\n",
    "    3: 'WALKING_DOWNSTAIRS' ,\n",
    "    4: 'SITTING'            ,\n",
    "    5: 'STANDING'           ,\n",
    "    6: 'LAYING'             ,\n",
    "}\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                        # Combining Traing Data\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_x_train.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_y_train.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_z_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_train = pd.read_csv(os.path.join(train_path,\"subject_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(train_path,\"y_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_train.values):\n",
    "\n",
    "    sub_idxs = np.where( subject_train.iloc[:,0] == subject )[0]\n",
    "    labels = y.loc[sub_idxs]\n",
    "\n",
    "    # Toggle through all the labels.\n",
    "    for label in np.unique(labels.values):\n",
    "\n",
    "        # make the folder directory if it does not exist\n",
    "        if not os.path.exists(os.path.join(\"Combined\",\"Train\",ACTIVITIES[label])):\n",
    "            os.makedirs(os.path.join(\"Combined\",\"Train\",ACTIVITIES[label]))\n",
    "\n",
    "        label_idxs = labels[labels.iloc[:,0] == label].index\n",
    "\n",
    "        accx = []\n",
    "        accy = []\n",
    "        accz = []\n",
    "\n",
    "        for idx in label_idxs:\n",
    "            if accx is not None:\n",
    "                accx = np.hstack((accx,total_acc_x.loc[idx][64:]))\n",
    "                accy = np.hstack((accy,total_acc_y.loc[idx][64:]))\n",
    "                accz = np.hstack((accz,total_acc_z.loc[idx][64:]))\n",
    "\n",
    "            else:\n",
    "                accx = total_acc_x.loc[idx]\n",
    "                accy = total_acc_y.loc[idx]\n",
    "                accz = total_acc_z.loc[idx]\n",
    "\n",
    "        # saving the data into csv file\n",
    "        data = pd.DataFrame({'accx':accx,'accy':accy,'accz':accz})\n",
    "        save_path = os.path.join(\"Combined\",\"Train\",ACTIVITIES[label],f\"Subject_{subject}.csv\")\n",
    "        data.to_csv(save_path,index=False)\n",
    "\n",
    "print(\"Done Combining the training data\")\n",
    "\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                        # Combining Test Data               \n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_x_test.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_y_test.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_z_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_test = pd.read_csv(os.path.join(test_path,\"subject_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(test_path,\"y_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_test.values):\n",
    "    \n",
    "        sub_idxs = np.where( subject_test.iloc[:,0] == subject )[0]\n",
    "        labels = y.loc[sub_idxs]\n",
    "\n",
    "        # Toggle through all the labels.\n",
    "        for label in np.unique(labels.values):\n",
    "    \n",
    "            if not os.path.exists(os.path.join(\"Combined\",\"Test\",ACTIVITIES[label])):\n",
    "                os.makedirs(os.path.join(\"Combined\",\"Test\",ACTIVITIES[label]))\n",
    "    \n",
    "            label_idxs = labels[labels.iloc[:,0] == label].index\n",
    "    \n",
    "            accx = []\n",
    "            accy = []\n",
    "            accz = []\n",
    "            for idx in label_idxs:\n",
    "                if accx is not None:\n",
    "                    accx = np.hstack((accx,total_acc_x.loc[idx][64:]))\n",
    "                    accy = np.hstack((accy,total_acc_y.loc[idx][64:]))\n",
    "                    accz = np.hstack((accz,total_acc_z.loc[idx][64:]))\n",
    "    \n",
    "                else:\n",
    "                    accx = total_acc_x.loc[idx]\n",
    "                    accy = total_acc_y.loc[idx]\n",
    "                    accz = total_acc_z.loc[idx]\n",
    "    \n",
    "            # saving the data into csv file\n",
    "            data = pd.DataFrame({'accx':accx,'accy':accy,'accz':accz})\n",
    "            save_path = os.path.join(\"Combined\",\"Test\",ACTIVITIES[label],f\"Subject_{subject}.csv\")\n",
    "            data.to_csv(save_path,index=False)\n",
    "\n",
    "print(\"Done Combining the testing data\")\n",
    "print(\"Done Combining the data\")\n",
    "\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Combining the training data\n",
      "Done Combining the testing data\n",
      "Done Combining the data\n"
     ]
    }
   ],
   "source": [
    "%run CombineScript.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
